{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Sentiment Analysis with Structural Features\n",
      "###Rohit Pathak, Bharadwaj Tanikella\n",
      "We train a classifier with features extracted from a RST parse tree to perform sentiment analysis on user reviews. All features and the intuition behind them are discussed along the way.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from sklearn.linear_model import Perceptron\n",
      "from nltk.classify.scikitlearn import SklearnClassifier\n",
      "from nltk import NaiveBayesClassifier\n",
      "from nltk.classify import apply_features\n",
      "from nltk.tokenize import sent_tokenize, word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "from collections import defaultdict, Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Helper methods and miscellaneous stuff to clean up text\n",
      "from HTMLParser import HTMLParser\n",
      "\n",
      "class MLStripper(HTMLParser):\n",
      "    def __init__(self):\n",
      "        self.reset()\n",
      "        self.fed = []\n",
      "    def handle_data(self, d):\n",
      "        self.fed.append(d)\n",
      "    def get_data(self):\n",
      "        return ''.join(self.fed)\n",
      "\n",
      "stripper = MLStripper() # ;)\n",
      "def strip_tags(html):\n",
      "    stripper.feed(html)\n",
      "    return stripper.get_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Feature Extractor object computes features for a document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FeatureExtractor():\n",
      "    \n",
      "    def __init__(self,):\n",
      "        self.features = {}\n",
      "    \n",
      "    def bow_features(self, text):\n",
      "        w = Counter()\n",
      "        for sent in sent_tokenize(text.decode(\"utf8\")):\n",
      "            words = word_tokenize(sent)\n",
      "            w.update(words)\n",
      "        feats = { ('BOW', word) : val for word,val in w.items() } \n",
      "        return feats\n",
      "            \n",
      "    # TODO: Add RST features here\n",
      "    def rst_features(self, text):\n",
      "        return {}\n",
      "    \n",
      "    def extract(self, review):\n",
      "        text = strip_tags(review)\n",
      "        features = self.bow_features(text)\n",
      "        return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our dataset contains 50k imdb reviews. Currently we are training a Naive Bayes Classifier with 50 random reviews and testing the accuracy on 50 other randomly selected reviews. The classification task is binary - each review is either POSitive or NEGagive.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import random\n",
      "\n",
      "DATA_DIR = 'data_sample/'\n",
      "train_files = {'pos': [DATA_DIR + 'train/pos/' + f for f in os.listdir(DATA_DIR+'train/pos/') if 'edus' in f], \n",
      "               'neg': [DATA_DIR + 'train/neg/' + f for f in os.listdir(DATA_DIR+'train/neg/') if 'edus' in f]}\n",
      "test_files = {'pos': [DATA_DIR + 'test/pos/' + f for f in os.listdir(DATA_DIR+'test/pos/') if 'edus' in f], \n",
      "               'neg': [DATA_DIR + 'test/neg/' + f for f in os.listdir(DATA_DIR+'test/neg/') if 'edus' in f]}\n",
      "\n",
      "fet = FeatureExtractor()\n",
      "\n",
      "def generate_labelled_data( files ):\n",
      "    data = []\n",
      "    for filename in (files):\n",
      "        label = 'pos' if 'pos' in filename else 'neg'\n",
      "        f = open(filename, 'r')\n",
      "        review = f.read()\n",
      "        f.close()\n",
      "        data.append( (fet.extract(review), label) )\n",
      "        print filename, label.upper(), ' | ',\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generating training set\n",
      "train_set = generate_labelled_data(train_files['pos'] + train_files['neg'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/11228_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/11690_9.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/12246_9.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/2155_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/2278_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/2956_8.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/4698_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/6674_9.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/8193_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/pos/9782_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/1815_2.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/1849_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/2118_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/3212_3.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/4400_4.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/80_3.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/8185_2.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/873_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/9481_3.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/train/neg/9986_2.edus NEG  | \n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generating test set\n",
      "test_set = generate_labelled_data(test_files['pos'] + test_files['neg'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/11228_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/11690_9.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/12246_9.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/2155_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/2278_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/2956_8.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/4698_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/6674_9.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/8193_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/pos/9782_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/neg/1815_2.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/neg/1849_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/neg/2118_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/neg/3212_3.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/neg/4400_4.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/neg/80_3.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_sample/test/neg/8185_2.edus NEG  |  "
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Training a classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Accuracy\n",
      "[We will test the accuracy of our classifier incrementally. But for now, it's pretty direct.]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifier, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.54\n"
       ]
      }
     ],
     "prompt_number": 70
    }
   ],
   "metadata": {}
  }
 ]
}