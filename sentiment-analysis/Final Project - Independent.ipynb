{
 "metadata": {
  "name": "",
  "signature": "sha256:30d7c721cfba484480f2ec7697d031392ce19073ce4d79cadd429fe855e4fdc0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Sentiment Analysis with Structural Features\n",
      "###Rohit Pathak, Bharadwaj Tanikella\n",
      "We train a classifier with features extracted from a RST parse tree to perform sentiment analysis on user reviews. All features and the intuition behind them are discussed along the way.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.classify.scikitlearn import SklearnClassifier\n",
      "from nltk import NaiveBayesClassifier\n",
      "from nltk.classify import apply_features\n",
      "from nltk.tokenize import sent_tokenize, word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.metrics import roc_curve\n",
      "from collections import defaultdict, Counter\n",
      "import re\n",
      "import os\n",
      "import random\n",
      "import utils\n",
      "import math\n",
      "\n",
      "import sys\n",
      "sys.path.insert(0,'../RSTParser')\n",
      "import docparser\n",
      "\n",
      "reload(utils)\n",
      "reload(docparser)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 371,
       "text": [
        "<module 'docparser' from '../RSTParser/docparser.pyc'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 371
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Feature Extractor object computes features for a document."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our dataset contains 50k imdb reviews. Currently we are training a Naive Bayes Classifier with 4000 random reviews and testing the accuracy on 800 other randomly selected reviews. The classification task is binary - each review is either POSitive or NEGagive.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATA_DIR = 'data_sample/'\n",
      "\n",
      "train_files = [DATA_DIR + 'train/pos/' + f for f in os.listdir(DATA_DIR+'train/pos/') if f.endswith('.edus')]\n",
      "train_files += [DATA_DIR + 'train/neg/' + f for f in os.listdir(DATA_DIR+'train/neg/') if f.endswith('.edus')]\n",
      "test_files = [DATA_DIR + 'test/pos/' + f for f in os.listdir(DATA_DIR+'test/pos/') if f.endswith('.edus')]\n",
      "test_files += [DATA_DIR + 'test/neg/' + f for f in os.listdir(DATA_DIR+'test/neg/') if f.endswith('.edus')]\n",
      "\n",
      "random.shuffle(train_files)\n",
      "random.shuffle(test_files)\n",
      "\n",
      "def generate_labelled_data( files, feat_func ):\n",
      "    data = []\n",
      "    for i,filename in enumerate(files):\n",
      "        label = 'pos' if 'pos' in filename else 'neg'\n",
      "        f = open(filename, 'r')\n",
      "        review = f.read()\n",
      "        f.close()\n",
      "        f = open(filename.replace('edus','pos'), 'r')\n",
      "        pos_tags = f.read()\n",
      "        f.close()\n",
      "        f = open(filename.replace('edus', 'headwords'), 'r')\n",
      "        headwords = f.read()\n",
      "        f.close()\n",
      "        data.append( (feat_func(review, pos_tags, headwords), label) )\n",
      "        if i >0 and i%100==0: print \"At %s instances\" %i,\n",
      "    return data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Baseline Features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Bag of Words Features\n",
      "We train a SVM with simple BOW features with stopwords removed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bow_feats(document,pos_tags, headwords):\n",
      "    text = document.lower()\n",
      "    words = ['[[BOW]] ' + w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "    return dict( Counter(words) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, bow_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances\n"
       ]
      }
     ],
     "prompt_number": 275
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now train a SVM with the training data generated above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 276
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And test it on the test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_set = generate_labelled_data( test_files, bow_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 277
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.815\n"
       ]
      }
     ],
     "prompt_number": 278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.81249999796875, 'f-measure': 0.8145358388141335, 'precision': 0.8165829125211485}\n"
       ]
      }
     ],
     "prompt_number": 279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.78875\n"
       ]
      }
     ],
     "prompt_number": 280
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.70249999824375, 'f-measure': 0.76880935187293, 'precision': 0.8489425956225299}\n"
       ]
      }
     ],
     "prompt_number": 281
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Length of the Document"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Intuition: A very basic feature to see if the length of the review can effect the classification of the sentiment of the review."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doc_length(document, pos_tags, headwords):\n",
      "    text = document.lower()\n",
      "    words = [w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "    length={}\n",
      "    length['[[LENGTH]]']=len(words)\n",
      "    return dict(dict( length  ).items()+bow_feats(document,pos_tags,headwords).items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 335
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, doc_length )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances\n"
       ]
      }
     ],
     "prompt_number": 336
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 337
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_set = generate_labelled_data( test_files, doc_length )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 338
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.8125\n"
       ]
      }
     ],
     "prompt_number": 339
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.8174999979562501, 'f-measure': 0.8134323338101141, 'precision': 0.8094059385905794}\n"
       ]
      }
     ],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.82125\n"
       ]
      }
     ],
     "prompt_number": 341
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.789999998025, 'f-measure': 0.8154833693838648, 'precision': 0.8426666644195556}\n"
       ]
      }
     ],
     "prompt_number": 342
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Moving on to RST features (individual)\n",
      "We now individually try a range of features extracted from the parse tree to see how they compare against the pure BOW model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Nucleus Bag of Words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nucleus_bow_feats(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags, headwords)\n",
      "    for node in nodelist:\n",
      "        if node.prop == 'Nucleus':\n",
      "            text = node.text.lower()\n",
      "            words = ['[[NUC_BOW]] ' + w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "            return dict( Counter(words))\n",
      "    else:\n",
      "        print \"Empty Doc?\",\n",
      "        return bow_feats(document,pos_tags, headwords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, nucleus_bow_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc?\n"
       ]
      }
     ],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_set = generate_labelled_data( test_files, nucleus_bow_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc?\n"
       ]
      }
     ],
     "prompt_number": 318
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 319
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.56375\n"
       ]
      }
     ],
     "prompt_number": 320
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.649999998375, 'f-measure': 0.5983884545948633, 'precision': 0.5543710009501684}\n"
       ]
      }
     ],
     "prompt_number": 321
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5975\n"
       ]
      }
     ],
     "prompt_number": 322
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.6049999984875, 'f-measure': 0.6004957764536917, 'precision': 0.5960591118323667}\n"
       ]
      }
     ],
     "prompt_number": 323
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Relation BOW\n",
      "Intuition: words in combination of the relation that they can be more reflective of the sentiment that they are associated with. If a word is consistently in a relation, it may affect the 'degree' of that sentiment."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def relation_bow_feats(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags, headwords)\n",
      "    relation_bow = Counter()\n",
      "    relation_bow['[[RELATION_WEIGHT]] OFFSET'] = 1 \n",
      "    for node in nodelist:\n",
      "        if node.relation is not None:\n",
      "            text= node.text.lower()\n",
      "            words = ['[[RELATION_WEIGHT]] ' + node.relation + ' ' + w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "            relation_bow.update(words)\n",
      "    #print relation_bow\n",
      "    return dict(dict(relation_bow)+ nucleus_bow(document,pos_tags,headwords).items()+ bow_feats(document,pos_tags,headwords).items()+doc_length(document,pos_tags,headwords).items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, relation_bow_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances\n"
       ]
      }
     ],
     "prompt_number": 344
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, relation_bow_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 345
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.8025\n"
       ]
      }
     ],
     "prompt_number": 346
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.849999997875, 'f-measure': 0.8114553463471607, 'precision': 0.7762557059902838}\n"
       ]
      }
     ],
     "prompt_number": 347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.8\n"
       ]
      }
     ],
     "prompt_number": 348
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.74749999813125, 'f-measure': 0.788917705258563, 'precision': 0.8351955283933086}\n"
       ]
      }
     ],
     "prompt_number": 349
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Level of the Tree and BOW"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Intuition: An updated bag of words approachto find the similarity between the level in the tree and the connection between the frequency of words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def depth_bow(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags, headwords)\n",
      "    depth_bow = Counter()\n",
      "    depth_bow['[[DEPTH_BOW]] OFFSET'] = 1 \n",
      "    for i,node in enumerate(nodelist):\n",
      "        depth = math.floor(math.log(i+1,2))\n",
      "        depth = int(depth)\n",
      "        if node.text is not None:\n",
      "            text= node.text.lower()\n",
      "            words = ['[[DEPTH_BOW]] ' + str(depth) + ' ' + w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "            depth_bow.update(words)\n",
      "    #print relation_bow\n",
      "    return dict(depth_bow)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 350
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, depth_bow )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances\n"
       ]
      }
     ],
     "prompt_number": 351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, depth_bow )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.81375\n"
       ]
      }
     ],
     "prompt_number": 355
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.83249999791875, 'f-measure': 0.8171774122747609, 'precision': 0.8024096366206996}\n"
       ]
      }
     ],
     "prompt_number": 356
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.81375\n"
       ]
      }
     ],
     "prompt_number": 357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.77249999806875, 'f-measure': 0.8057361350699773, 'precision': 0.8419618505668615}\n"
       ]
      }
     ],
     "prompt_number": 358
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Polarity Features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Intuition: The main intuition behind this is to use the polarity of the words to efficiently tag the nucleus whether the nucleus has more number of positive or negative polarity. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "poswords = set()\n",
      "negwords = set()\n",
      "neutralwords = set()\n",
      "with open('sentiment-vocab.tff','r') as fin:\n",
      "    for i,line in enumerate(fin):\n",
      "        # more list and dict comprehensions!\n",
      "        kvs = {key:val for key,val in [kvp.split('=') for kvp in line.split() if '=' in kvp]}\n",
      "        if kvs['type'] == 'strongsubj':\n",
      "            if kvs['priorpolarity'] == 'negative':\n",
      "                negwords.add(kvs['word1'])\n",
      "            if kvs['priorpolarity'] == 'positive':\n",
      "                poswords.add(kvs['word1'])\n",
      "            if kvs['priorpolarity'] == 'neutral':\n",
      "                neutralwords.add(kvs['word1'])\n",
      "all_labels = ['pos', 'neg','neu']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 184
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Nucleus Polarity"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nucleus_polarity(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags,headwords)\n",
      "    nucleus_polarity = Counter()\n",
      "    nucleus_polarity['[[NUCLEUS_POLARITY]] OFFSET'] = 1 \n",
      "    for node in nodelist:\n",
      "        if node.prop == 'Nucleus':\n",
      "            text = node.text.lower()\n",
      "            words = [ w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "            for word in words:\n",
      "                if word in poswords:\n",
      "                    nucleus_polarity['[[NUCLEUS_POLARITY]] POS']+=1\n",
      "                if word in negwords:\n",
      "                    nucleus_polarity['[[NUCLEUS_POLARITY]] NEG']+=1\n",
      "                if word in neutralwords:\n",
      "                    nucleus_polarity['[[NUCLEUS_POLARITY]] NEU']+=1\n",
      "            return dict(nucleus_polarity)\n",
      "    else:\n",
      "        print \"Empty Doc?\",\n",
      "        return bow_feats(document,pos_tags,headwords)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 359
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, nucleus_polarity )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc?\n"
       ]
      }
     ],
     "prompt_number": 360
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, nucleus_polarity )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc?\n"
       ]
      }
     ],
     "prompt_number": 361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5725\n"
       ]
      }
     ],
     "prompt_number": 362
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.429999998925, 'f-measure': 0.5014572382940394, 'precision': 0.6013985992958091}\n"
       ]
      }
     ],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5575\n"
       ]
      }
     ],
     "prompt_number": 364
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.3549999991125, 'f-measure': 0.4451405966730869, 'precision': 0.5966386529552998}\n"
       ]
      }
     ],
     "prompt_number": 365
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Level Centric Polarity Relations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Intuition: The main reason to find the level centric polarity relations is to see if there is a high correlation between the level the edu's are located and the relative polarity(sentiment) of them. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def level_edu_polarity(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None and not len(document)==0:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags, headwords)\n",
      "    level_edu_polarityDict = Counter()\n",
      "    level_edu_polarityDict['[[LEVEL_RELATION_POLARITY]] OFFSET'] = 1 \n",
      "    depth = math.floor(math.log(len(nodelist)+1,2))\n",
      "    for i,node in enumerate(nodelist): \n",
      "        current_depth= math.floor(math.log(i+1,2)) \n",
      "        if node.prop is not None and current_depth<depth-1 and depth > 1:\n",
      "            text = node.text.lower()\n",
      "            words = [ w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "            pos = 0\n",
      "            neg = 0\n",
      "            for word in words:\n",
      "                if word in poswords:\n",
      "                    pos+=1\n",
      "                if word in negwords:\n",
      "                    neg+=1\n",
      "            if node.relation == 'contrast' and pos>neg and node.rnode is not None:\n",
      "                level_edu_polarityDict['[[LEVEL_RELATION_POLARITY]]'+ node.rnode.relation +str(current_depth)+' NEG']=1\n",
      "            if node.relation == 'contrast' and neg>pos and node.rnode is not None:\n",
      "                level_edu_polarityDict['[[LEVEL_RELATION_POLARITY]]'+ node.rnode.relation +str(current_depth)+' POS']=1\n",
      "            else:\n",
      "                if neg>pos:\n",
      "                    level_edu_polarityDict['[[LEVEl_RELATION_POLARITY]]'+ node.relation +str(current_depth)+' NEG']=1\n",
      "                if pos>neg:\n",
      "                    level_edu_polarityDict['[[LEVEl_RELATION_POLARITY]]'+ node.relation +str(current_depth)+' POS']=1\n",
      "                else:\n",
      "                    level_edu_polarityDict['[[LEVEl_RELATION_POLARITY]]'+ node.relation +str(current_depth)+' NEG']=0.5\n",
      "                    level_edu_polarityDict['[[LEVEl_RELATION_POLARITY]]'+ node.relation +str(current_depth)+' POS']=0.5\n",
      "                \n",
      "    \n",
      "    return dict(level_edu_polarityDict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 288
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, level_edu_polarity )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances\n"
       ]
      }
     ],
     "prompt_number": 289
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, level_edu_polarity )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 290
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.6575\n"
       ]
      }
     ],
     "prompt_number": 291
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.729999998175, 'f-measure': 0.6806521813512587, 'precision': 0.6375545837607979}\n"
       ]
      }
     ],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.645\n"
       ]
      }
     ],
     "prompt_number": 293
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.6149999984625, 'f-measure': 0.6340201174012863, 'precision': 0.6542553174088954}\n"
       ]
      }
     ],
     "prompt_number": 294
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Sentiment Word Net Features. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usage of SWN http://sentiwordnet.isti.cnr.it/ resource to label the words with weights of Positive and Negative polarity. For our implementation we considered the positive and negative scores of the word. We tried to implement the sentimental weights to improve the features regarding the relation. \n",
      "\n",
      "Intuition: The main reason we tried to implement the relational sentimental weights is because, we thought that the main polarity between different relations can help us find a pattern between the data sets. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#def sentimentWeights(word)\n",
      "\n",
      "with open('SentiWordNet_3.0.0_20130122.txt','r') as fin:\n",
      "    word_sentiment_weight=defaultdict(float)\n",
      "    num_words  = defaultdict(int)\n",
      "    j=0\n",
      "    for i,line in enumerate(fin):\n",
      "        if len(line)>50 and not '# ' in line:\n",
      "            tokens = word_tokenize(line)\n",
      "            for value in tokens:\n",
      "                if value =='#':\n",
      "                    word_sentiment_weight[(tokens[tokens.index(value)-1],'POS')]+=float(tokens[2])\n",
      "                    num_words[tokens[tokens.index(value)-1]]+=1\n",
      "                    word_sentiment_weight[(tokens[tokens.index(value)-1],'NEG')]+=float(tokens[3])\n",
      "    for value in num_words.keys():\n",
      "        word_sentiment_weight[value,'POS']=word_sentiment_weight[value,'POS']/num_words[value]\n",
      "        word_sentiment_weight[value,'NEG']=word_sentiment_weight[value,'NEG']/num_words[value]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def relation_sentiment_weight_feats(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags, headwords)\n",
      "    relation_sentiment_weight = Counter()\n",
      "    relation_sentiment_weight['[[RELATION_SENT_WEIGHT]] OFFSET'] = 1 \n",
      "    for i,node in enumerate(nodelist):\n",
      "        level = math.floor(math.log(i+1,2))\n",
      "        level = int(level)\n",
      "        \n",
      "        if node.relation is not None:\n",
      "            \n",
      "            text = node.text.lower()\n",
      "            words = [w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "            \n",
      "            for word in words:\n",
      "                relation_sentiment_weight['[[RELATION_SENT_WEIGHT]] ' + node.relation  + 'POS'] += word_sentiment_weight[word,'POS']\n",
      "                relation_sentiment_weight['[[RELATION_SENT_WEIGHT]] ' + node.relation  + 'NEG'] += word_sentiment_weight[word,'NEG']\n",
      "    return dict(relation_sentiment_weight)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, relation_sentiment_weight_feats )\n",
      "\n",
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, relation_sentiment_weight_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 303
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.545\n"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.91749999770625, 'f-measure': 0.6684876959037849, 'precision': 0.5257879648627679}\n"
       ]
      }
     ],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.4975\n"
       ]
      }
     ],
     "prompt_number": 306
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.85249999786875, 'f-measure': 0.6291508246725305, 'precision': 0.4985380109670497}\n"
       ]
      }
     ],
     "prompt_number": 307
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Parts of Speech Tagging Features for Relations in RST Parse Tree."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Intuition: The main reason for these particular features is because of the relationship between the parse tree relations and a skewed model of POS tags."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def relation_POS(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags, headwords)\n",
      "    relation_POS= Counter()\n",
      "    relation_POS['[[RELATION_POS]] OFFSET'] = 1 \n",
      "    for node in nodelist:\n",
      "        if node.relation is not None:\n",
      "            text = node.text.lower()\n",
      "            posTags= node.posTags\n",
      "            for (i,pos) in enumerate(posTags):\n",
      "                if pos == 'UH' or pos.startswith('JJ') or pos.startswith('RB'):\n",
      "                    relation_POS['[[RELATION_POS]] '+node.relation+' '+pos] += 2\n",
      "                else:\n",
      "                    relation_POS['[[RELATION_POS]] '+node.relation+' '+pos] += 1 \n",
      "        \n",
      "            \n",
      "    return dict(relation_POS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 295
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, relation_POS )\n",
      "\n",
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, relation_POS )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 296
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.55625\n"
       ]
      }
     ],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.24249999939375, 'f-measure': 0.3533693664325373, 'precision': 0.6510067070402235}\n"
       ]
      }
     ],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5425\n"
       ]
      }
     ],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.33249999916875, 'f-measure': 0.4208856099488384, 'precision': 0.5732758595979489}\n"
       ]
      }
     ],
     "prompt_number": 300
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Experimental Features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Number of Relations\n",
      "Our proposition is that more of certain kinds of relations are usually positive reviews."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def num_relations_feats(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    \n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags, headwords)\n",
      "    relation_count=defaultdict(int)\n",
      "    relation_count['[[NUM_RELATION]] OFFSET'] = 1\n",
      "    for node in nodelist:\n",
      "        if node.relation is not None:\n",
      "            relation_count[ '[[Num_Relation]] ' + node.relation]+=1\n",
      "    return dict(relation_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, num_relations_feats )\n",
      "\n",
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, num_relations_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.81375\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.8224999979437501, 'f-measure': 0.8153650494422252, 'precision': 0.8083538063676811}\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.8175\n"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.789999998025, 'f-measure': 0.812338829931381, 'precision': 0.8359788337672518}\n"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Weight of the Relations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Intuition: An experimental way to test how the weight of a particular relation in the parse tree effect the classification. Null Hypothesis: A stronger (pos/neg) review has more elaboration. \n",
      "\n",
      "Answer: The hypothesis has been proven wrong. Value of 0.5 accuracy with a F- measure of 0.019."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def relation_weight_feats(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags, headwords)\n",
      "    relation_weight = Counter()\n",
      "    relation_weight['[[RELATION_BOW]] OFFSET'] = 1 \n",
      "    for node in nodelist:\n",
      "        if node.relation is not None:\n",
      "            text = node.text.lower()\n",
      "            relation_weight['[[RELATION_BOW]] ' + node.relation ] += len(text)\n",
      "    #print relation_bow\n",
      "    return dict(dict(relation_weight).items()+bow_feats(document,pos_tags, headwords).items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, relation_weight_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances\n"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, relation_weight_feats )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.58375\n"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.949999997625, 'f-measure': 0.6953334779339956, 'precision': 0.5483405475492922}\n"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifierNB,test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.81875\n"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.7949999980125, 'f-measure': 0.8143400871993243, 'precision': 0.8346456671006676}\n"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature Recommended by Rishikesh on Homework 14."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def word_polarity(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    if tree is None and nodelist is None:\n",
      "        tree, nodelist = docparser.getParseTree(document,pos_tags,headwords)\n",
      "    word_polarity = Counter()\n",
      "    word_polarity['[[WORD_POLARITY]] OFFSET'] = 1 \n",
      "    for node in nodelist:\n",
      "        text = node.text.lower()\n",
      "        words = [ w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "        for word in words:\n",
      "            if word in poswords:\n",
      "                word_polarity['[[WORD_POLARITY]] POS ']+=1\n",
      "            if word in negwords:\n",
      "                word_polarity['[[WORD_POLARITY]] NEG ']+=1\n",
      "            else:\n",
      "                word_polarity['[[WORD_POLARITY]] POS ']+=0.5\n",
      "                word_polarity['[[WORD_POLARITY]] NEG ']+=0.5\n",
      "    return dict(dict(word_polarity).items()+bow_feats(document,pos_tags, headwords).items()+doc_length(document,pos_tags,headwords).items())\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 369
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, word_polarity )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-370-153cb51e3b15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_labelled_data\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_polarity\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-131-455f8ec021cf>\u001b[0m in \u001b[0;36mgenerate_labelled_data\u001b[0;34m(files, feat_func)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mheadwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"At %s instances\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-369-7b198160e499>\u001b[0m in \u001b[0;36mword_polarity\u001b[0;34m(document, pos_tags, headwords, tree, nodelist)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mword_polarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'[[WORD_POLARITY]] POS '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mword_polarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'[[WORD_POLARITY]] NEG '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_polarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbow_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdoc_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheadwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-335-a5f480e9ecbe>\u001b[0m in \u001b[0;36mdoc_length\u001b[0;34m(document, pos_tags, headwords)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlength\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'[[LENGTH]]'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlength\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbow_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheadwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-334-e60a694e97fe>\u001b[0m in \u001b[0;36mbow_feats\u001b[0;34m(document, pos_tags, headwords)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbow_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'[[BOW]] '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\w+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Bharadwaj/anaconda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.pyc\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Bharadwaj/anaconda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.pyc\u001b[0m in \u001b[0;36mraw\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Bharadwaj/anaconda/lib/python2.7/site-packages/nltk/corpus/reader/api.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[1;32m    197\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Bharadwaj/anaconda/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeekableUnicodeStreamReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 370
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, word_polarity )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances\n"
       ]
      }
     ],
     "prompt_number": 352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))\n",
      "precisionRecallF(classif)\n",
      "print(nltk.classify.accuracy(classifierNB,test_set))\n",
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5\n",
        "{'recall': 0.9999999975, 'f-measure': 0.6666662211114073, 'precision': 0.499999999375}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'recall': 0.9999999975, 'f-measure': 0.6666662211114073, 'precision': 0.499999999375}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 353
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Evaluation\n",
      "\n",
      "Different Evaluation methods are used to compare and contrast the scores of the features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generating test set\n",
      "def evaluation_without_baseline(document,pos_tags, headwords, tree=None, nodelist=None):\n",
      "    return dict(nucleus_bow_feats(document,pos_tags, headwords).items()+ depth_bow(document,pos_tags, headwords).items() + nucleus_polarity(document,pos_tags, headwords).items() + level_edu_polarity(document,pos_tags, headwords).items() + relation_POS(document,pos_tags, headwords).items()+bow_feats(document,pos_tags,headwords).items()+doc_length(document,pos_tags,headwords).items() ) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 367
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files, evaluation_without_baseline )\n",
      "\n",
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)\n",
      "classifierNB= nltk.classify.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "test_set = generate_labelled_data( test_files, evaluation_without_baseline )\n",
      "\n",
      "print(nltk.classify.accuracy(classif, test_set))\n",
      "precisionRecallF(classif)\n",
      "print(nltk.classify.accuracy(classifierNB,test_set))\n",
      "precisionRecallF(classifierNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 2900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 3900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Empty Doc? Empty Doc? "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.78375\n",
        "{'recall': 0.78749999803125, 'f-measure': 0.7845574058988095, 'precision': 0.7816377151820404}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.8025"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'recall': 0.74749999813125, 'f-measure': 0.7910047906066799, 'precision': 0.8398876380902033}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 368
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Precision, Recall and F-measure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def precisionRecallF(classifier):\n",
      "    tp= 0.0\n",
      "    tn= 0.0\n",
      "    fp= 0.0\n",
      "    fn= 0.0\n",
      "\n",
      "    results = classifier.classify_many([fs for (fs,l) in test_set])\n",
      "    actual = [l for (f,l) in test_set]\n",
      "\n",
      "    i=0\n",
      "\n",
      "    for i in range(len(results)):\n",
      "        if results[i]=='pos' and actual[i]=='pos':\n",
      "            tp+=1.0\n",
      "        if results[i]=='pos' and actual[i]=='neg':\n",
      "            fp+=1.0\n",
      "        if results[i]=='neg' and actual[i]=='pos':\n",
      "            fn+=1.0\n",
      "        if results[i]=='neg' and actual[i]=='neg':\n",
      "            tn+=1.0\n",
      "\n",
      "    recall = tp / (tp + fn+1e-6)\n",
      "    precision = tp / (tp + fp + 1e-6)\n",
      "    fmeasure = 2 * recall * precision / (recall + precision + 1e-6)\n",
      "    quality = {'f-measure': fmeasure, 'recall': recall, 'precision' : precision}\n",
      "\n",
      "    print quality"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}