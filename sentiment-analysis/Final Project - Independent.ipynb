{
 "metadata": {
  "name": "",
  "signature": "sha256:a113eea7e12baab1abbc32b6260bdc2f3b07669caa900d4635f52f793df65a5c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Sentiment Analysis with Structural Features\n",
      "###Rohit Pathak, Bharadwaj Tanikella\n",
      "We train a classifier with features extracted from a RST parse tree to perform sentiment analysis on user reviews. All features and the intuition behind them are discussed along the way.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Helper methods and miscellaneous stuff to clean up text\n",
      "from HTMLParser import HTMLParser\n",
      "\n",
      "class MLStripper(HTMLParser):\n",
      "    def __init__(self):\n",
      "        self.reset()\n",
      "        self.fed = []\n",
      "    def handle_data(self, d):\n",
      "        self.fed.append(d)\n",
      "    def get_data(self):\n",
      "        return ''.join(self.fed)\n",
      "\n",
      "stripper = MLStripper() # ;)\n",
      "def strip_tags(html):\n",
      "    stripper.feed(html)\n",
      "    return stripper.get_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from sklearn.linear_model import Perceptron\n",
      "from nltk.classify.scikitlearn import SklearnClassifier\n",
      "from nltk import NaiveBayesClassifier\n",
      "from nltk.classify import apply_features\n",
      "from nltk.tokenize import sent_tokenize, word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "from collections import defaultdict, Counter\n",
      "import sys\n",
      "sys.path.insert(0,'../RSTParser')\n",
      "\n",
      "import subParseTree\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Feature Extractor object computes features for a document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FeatureExtractor():\n",
      "    \n",
      "    def __init__(self,):\n",
      "        self.features = {}\n",
      "    \n",
      "    def bow_features(self, text):\n",
      "        w = Counter()\n",
      "        for sent in sent_tokenize(text.decode(\"utf8\")):\n",
      "            words = word_tokenize(sent)\n",
      "            w.update(words)\n",
      "        feats = { ('BOW', word) : val for word,val in w.items() } \n",
      "        return feats\n",
      "            \n",
      "    # TODO: Add RST features here\n",
      "    def rst_features(self, fileName):\n",
      "        \n",
      "        def nucleus_BOW(text):\n",
      "            nBow=defaultdict(int)\n",
      "            for word in word_tokenize(text):\n",
      "                nBow[('Nucleus',word)]+=1\n",
      "            return dict(nBow)\n",
      "        features={}\n",
      "        neucleus_bow={}\n",
      "        NodeList = subParseTree.getParseTreeList(fileName)\n",
      "        NodeList.reverse()\n",
      "        for node in NodeList:\n",
      "            if node.prop == 'Nucleus':\n",
      "                neucleus_bow=nucleus_BOW(node.text)\n",
      "                break\n",
      "        features=neucleus_bow\n",
      "        return features\n",
      "        \n",
      "    \n",
      "    def extract(self, review, fileName):\n",
      "        text = strip_tags(review)\n",
      "        features = self.bow_features(text)\n",
      "        features = dict( features.items() + self.rst_features(fileName).items() )\n",
      "        return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our dataset contains 50k imdb reviews. Currently we are training a Naive Bayes Classifier with 50 random reviews and testing the accuracy on 50 other randomly selected reviews. The classification task is binary - each review is either POSitive or NEGagive.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import random\n",
      "\n",
      "DATA_DIR = 'data_sample/'\n",
      "train_files = {'pos': [DATA_DIR + 'train/pos/' + f for f in os.listdir(DATA_DIR+'train/pos/') if 'edus' in f], \n",
      "               'neg': [DATA_DIR + 'train/neg/' + f for f in os.listdir(DATA_DIR+'train/neg/') if 'edus' in f]}\n",
      "test_files = {'pos': [DATA_DIR + 'test/pos/' + f for f in os.listdir(DATA_DIR+'test/pos/') if 'edus' in f], \n",
      "               'neg': [DATA_DIR + 'test/neg/' + f for f in os.listdir(DATA_DIR+'test/neg/') if 'edus' in f]}\n",
      "\n",
      "fet = FeatureExtractor()\n",
      "\n",
      "def generate_labelled_data( files ):\n",
      "    data = []\n",
      "    for filename in (files):\n",
      "        label = 'pos' if 'pos' in filename else 'neg'\n",
      "        f = open(filename, 'r')\n",
      "        review = f.read()\n",
      "        f.close()\n",
      "        data.append( (fet.extract(review, filename), label) )\n",
      "        print filename, label.upper(), ' | ',\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generating training set\n",
      "train_set = generate_labelled_data(train_files['pos'] + train_files['neg'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/11102_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/3065_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/3938_9.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/5326_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/5801_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/6723_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/7376_8.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/7855_8.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/8904_7.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/pos/9514_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/10242_3.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/11713_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/1410_4.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/3802_2.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/5217_4.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/5751_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/6158_4.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/749_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/7969_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/train/neg/8403_4.edus NEG  | \n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generating test set\n",
      "test_set = generate_labelled_data(test_files['pos'] + test_files['neg'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/10183_7.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/11502_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/11556_7.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/2387_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/3221_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/3632_7.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/4017_7.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/5661_10.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/8613_7.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/pos/9659_8.edus POS  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/197_3.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/2216_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/2847_2.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/298_4.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/3922_3.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/3968_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/4805_1.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/5581_4.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/8426_4.edus NEG  |  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load model from file: parsing-model.pickle.gz\n",
        "data_sample/test/neg/9375_4.edus NEG  | \n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Training a classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Accuracy\n",
      "[We will test the accuracy of our classifier incrementally. But for now, it's pretty direct.]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classifier, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}