{
 "metadata": {
  "name": "",
  "signature": "sha256:d53eef62638736f5c2d319c2fe74554e858d40bf7497f7643d93659cea338156"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Sentiment Analysis with Structural Features\n",
      "###Rohit Pathak, Bharadwaj Tanikella\n",
      "We train a classifier with features extracted from a RST parse tree to perform sentiment analysis on user reviews. All features and the intuition behind them are discussed along the way.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.classify.scikitlearn import SklearnClassifier\n",
      "from nltk import NaiveBayesClassifier\n",
      "from nltk.classify import apply_features\n",
      "from nltk.tokenize import sent_tokenize, word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "from collections import defaultdict, Counter\n",
      "import re\n",
      "import os\n",
      "import random\n",
      "import utils"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Feature Extractor object computes features for a document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FeatureExtractor():\n",
      "    \n",
      "    def __init__(self,):\n",
      "        pass\n",
      "    \n",
      "    def bow_features(self, text):\n",
      "        text = document.lower()\n",
      "        words = ['[[BOW]] '+ w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "        return dict( Counter(words) )\n",
      "    \n",
      "    # TODO: Add RST features here\n",
      "    def rst_features(self, fileName):\n",
      "        \n",
      "        def nucleus_BOW(text):\n",
      "            nBow=defaultdict(int)\n",
      "            for word in word_tokenize(text.decode(\"utf8\")):\n",
      "                nBow[str(('Nucleus_BOW',word))]+=1\n",
      "            return dict(nBow)\n",
      "        \n",
      "        def num_Relations(NodeList):\n",
      "            relationCount=defaultdict(int)\n",
      "            for node in NodeList:\n",
      "                if node.relation is not None:\n",
      "                    relationCount[str(('Num_Relation',node.relation))]+=1\n",
      "            return dict(relationCount)\n",
      "        \n",
      "        def relation_BOW(NodeList):\n",
      "            relationBow=defaultdict(int)\n",
      "            for node in NodeList:\n",
      "                for word in word_tokenize(node.text.decode(\"utf8\")):\n",
      "                    if node.relation is not None:\n",
      "                        relationBow[str(('Relation_BOW',node.relation,word))]+=1\n",
      "            return dict(relationBow)\n",
      "        \n",
      "        def weight_relation(NodeList):\n",
      "            relationWeight= defaultdict(int)\n",
      "            for node in NodeList:\n",
      "                if node.relation is not None:\n",
      "                    relationWeight[str(('Relation_Weight',node.relation))]+=1\n",
      "            return dict(relationWeight)\n",
      "        \n",
      "        def relation_POS(NodeList):\n",
      "            relationPos= defaultdict(int)\n",
      "            for node in NodeList:\n",
      "                for sent in sent_tokenize(node.text.decode(\"utf8\")):\n",
      "                    for (word,tag) in nltk.pos_tag(sent):\n",
      "                        relationPos[str(('Relation_POS',node.relation,tag))]+=1\n",
      "            return dict(relationPos)\n",
      "        \n",
      "        def polarityNucleus(NodeList):\n",
      "            value=defaultdict(int)\n",
      "            for node in NodeList:\n",
      "                if node.prop =='Nucleus':\n",
      "                    for word in word_tokenize(node.text.decode(\"utf8\")):\n",
      "                        if word in poswords:\n",
      "                            value['POS']+=1\n",
      "                        if word in negwords:\n",
      "                            value['NEG']+=1\n",
      "                    break\n",
      "                    \n",
      "            return dict(value)\n",
      "                                                           \n",
      "        features={}\n",
      "#         neucleus_bow={}\n",
      "#         NodeList = subParseTree.getParseTreeList(fileName)\n",
      "#         NodeList.reverse()\n",
      "#         for node in NodeList:\n",
      "#             if node.prop == 'Nucleus':\n",
      "#                 neucleus_bow=nucleus_BOW(node.text)\n",
      "#                 break\n",
      "\n",
      "#         features= dict(relation_POS(NodeList).items())\n",
      "        return features\n",
      "        \n",
      "    \n",
      "    def extract(self, review, filename=None):\n",
      "        text = utils.clean_text(review)\n",
      "        features = self.bow_features(text) #dict( self.rst_features(fileName).items() )\n",
      "        return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our dataset contains 50k imdb reviews. Currently we are training a Naive Bayes Classifier with 50 random reviews and testing the accuracy on 50 other randomly selected reviews. The classification task is binary - each review is either POSitive or NEGagive.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATA_DIR = 'data_sample/'\n",
      "\n",
      "train_files = [DATA_DIR + 'train/pos/' + f for f in os.listdir(DATA_DIR+'train/pos/') if 'edus' in f]\n",
      "train_files += [DATA_DIR + 'train/neg/' + f for f in os.listdir(DATA_DIR+'train/neg/') if 'edus' in f]\n",
      "test_files = [DATA_DIR + 'test/pos/' + f for f in os.listdir(DATA_DIR+'test/pos/') if 'edus' in f]\n",
      "test_files += [DATA_DIR + 'test/neg/' + f for f in os.listdir(DATA_DIR+'test/neg/') if 'edus' in f]\n",
      "\n",
      "random.shuffle(train_files)\n",
      "random.shuffle(test_files)\n",
      "\n",
      "fet = FeatureExtractor()\n",
      "\n",
      "def generate_labelled_data( files ):\n",
      "    data = []\n",
      "    for i,filename in enumerate(files):\n",
      "        label = 'pos' if 'pos' in filename else 'neg'\n",
      "        f = open(filename, 'r')\n",
      "        review = f.read()\n",
      "        f.close()\n",
      "        data.append( (fet.extract(review), label) )\n",
      "        if i >0 and i%100==0: print \"At %s instances\" %i,\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "clean_text() takes no arguments (1 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-15-da1037e0568f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_labelled_data\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_files\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-14-a0c5ad38825d>\u001b[0m in \u001b[0;36mgenerate_labelled_data\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"At %s instances\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-13-df61faff2c4b>\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, review, filename)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbow_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#dict( self.rst_features(fileName).items() )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: clean_text() takes no arguments (1 given)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Training a classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifiers\n",
      "\n",
      "# classifier_nb = NaiveBayesClassifier.train(train_set)\n",
      "# classifier_perceptron = SklearnClassifier(Perceptron()).train(train_set)\n",
      "reload(classifiers)\n",
      "classifier = classifiers.Perceptron(all_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w_ap, tr_acc_ap = classifier.train(6, train_set, all_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 train: 0.527638190955\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " train: 0.527638190955\n",
        "2"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Accuracy\n",
      "[We will test the accuracy of our classifier incrementally. But for now, it's pretty direct.]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generating test set\n",
      "test_set = []\n",
      "for inst,l in generate_labelled_data( sorted((test_files['pos'] + test_files['neg']), key=lambda k: random.random()) ):\n",
      "    test_set.append( (inst,l) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print(nltk.classify.accuracy(classifier_nb, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [l for a,l in test_set]\n",
      "print [ (l,classifier.classify(a)) for a,l in train_set]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'neg', 'neg', 'neg']\n",
        "[('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('pos', 'pos'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg'), ('pos', 'pos'), ('neg', 'neg')]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Precision, Recall and F-measure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tp= 0.0\n",
      "tn= 0.0\n",
      "fp= 0.0\n",
      "fn= 0.0\n",
      "\n",
      "results = classifier_perceptron.classify_many([fs for (fs,l) in test_set])\n",
      "actual = [l for (f,l) in test_set]\n",
      "\n",
      "i=0\n",
      "\n",
      "for i in range(len(results)):\n",
      "    if results[i]=='pos' and actual[i]=='pos':\n",
      "        tp+=1.0\n",
      "    if results[i]=='pos' and actual[i]=='neg':\n",
      "        fp+=1.0\n",
      "    if results[i]=='neg' and actual[i]=='pos':\n",
      "        fn+=1.0\n",
      "    if results[i]=='neg' and actual[i]=='neg':\n",
      "        tn+=1.0\n",
      "        \n",
      "recall = tp / (tp + fn)\n",
      "precision = tp / (tp + fp + 1e-6)\n",
      "fmeasure = 2 * recall * precision / (recall + precision + 1e-6)\n",
      "quality = {'f-measure': fmeasure, 'recall': recall, 'precision' : precision}\n",
      "\n",
      "print quality"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'recall': 0.0, 'f-measure': 0.0, 'precision': 0.0}\n"
       ]
      }
     ],
     "prompt_number": 392
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##LEFTOVERS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "poswords = set()\n",
      "negwords = set()\n",
      "with open('sentiment-vocab.tff','r') as fin:\n",
      "    for i,line in enumerate(fin):\n",
      "        # more list and dict comprehensions!\n",
      "        kvs = {key:val for key,val in [kvp.split('=') for kvp in line.split() if '=' in kvp]}\n",
      "        if kvs['type'] == 'strongsubj':\n",
      "            if kvs['priorpolarity'] == 'negative':\n",
      "                negwords.add(kvs['word1'])\n",
      "            if kvs['priorpolarity'] == 'positive':\n",
      "                poswords.add(kvs['word1'])\n",
      "\n",
      "all_labels = ['pos', 'neg']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    }
   ],
   "metadata": {}
  }
 ]
}