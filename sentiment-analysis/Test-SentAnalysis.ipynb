{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.classify.scikitlearn import SklearnClassifier\n",
      "from nltk.classify import apply_features\n",
      "from nltk.tokenize import sent_tokenize, word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "from collections import defaultdict, Counter\n",
      "import re\n",
      "import os\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATA_DIR = 'data_sample/'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_files = [DATA_DIR + 'train/pos/' + f for f in os.listdir(DATA_DIR+'train/pos/') if 'edus' in f]\n",
      "train_files += [DATA_DIR + 'train/neg/' + f for f in os.listdir(DATA_DIR+'train/neg/') if 'edus' in f]\n",
      "test_files = [DATA_DIR + 'test/pos/' + f for f in os.listdir(DATA_DIR+'test/pos/') if 'edus' in f]\n",
      "test_files += [DATA_DIR + 'test/neg/' + f for f in os.listdir(DATA_DIR+'test/neg/') if 'edus' in f]\n",
      "\n",
      "random.shuffle(train_files)\n",
      "random.shuffle(test_files)\n",
      "\n",
      "def generate_labelled_data( files ):\n",
      "    data = []\n",
      "    for i,filename in enumerate(files):\n",
      "        label = 'pos' if 'pos' in filename else 'neg'\n",
      "        f = open(filename, 'r')\n",
      "        review = f.read()\n",
      "        f.close()\n",
      "        data.append( (bow_feats(review ), label) )\n",
      "        if i >0 and i%100==0: print \"At %s instances\" %i,\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bow_feats(document):\n",
      "    text = document.lower()\n",
      "    words = [w for w in re.findall(r'\\w+', text) if not w in stopwords.words('english')]\n",
      "    return dict( Counter(words) )\n",
      "\n",
      "# f = open('test-data/train-imdb/5_10.txt', 'r')\n",
      "# sample = f.read()\n",
      "# f.close()\n",
      "# print bow_feats(sample)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = generate_labelled_data( train_files )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 900 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1000 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1100 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1200 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1300 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1400 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1500 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1600 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1700 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1800 instances "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 1900 instances\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_set = generate_labelled_data( test_files )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At 100 instances\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classif = SklearnClassifier(LinearSVC())\n",
      "classif.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "<SklearnClassifier(LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0))>"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.classify.accuracy(classif, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.76\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}